{"componentChunkName":"component---src-templates-blog-post-js","path":"/aimoment/","result":{"data":{"site":{"siteMetadata":{"title":"SK플래닛 TECH TOPIC"}},"markdownRemark":{"id":"9fd04d10-3c46-570b-921d-96a92939613b","excerpt":"'요즘' 개발자라면 GPT, Claude, Gemini와 같은 생성형 AI(LLM)를 한 번쯤은 사용해 보셨을 것입니다.\n하지만 AI를 사용자로 경험하는 것과 개발자 입장에서 이를 활용하여 LLM 기반 서비스를 구현하는 것은 '완전히' 다른 이야기였습니다. 이번 글에서는 저희가 개발자로 참여한 SK플래닛의 AI Moment…","html":"<p>'요즘' 개발자라면 GPT, Claude, Gemini와 같은 생성형 AI(LLM)를 한 번쯤은 사용해 보셨을 것입니다.\n</br>하지만 AI를 사용자로 경험하는 것과 개발자 입장에서 이를 활용하여 LLM 기반 서비스를 구현하는 것은 '완전히' 다른 이야기였습니다.</p>\n<p>이번 글에서는 저희가 개발자로 참여한 SK플래닛의 <strong>AI Moment</strong>라는 과제를 소개하고,  그리고 그 과정에서 마주친 문제들과 해결 방식에 대해 이야기해보려고 합니다.</p>\n<h2>1. AI Moment는 어떤 서비스인가요?</h2>\n<p>AI Moment는 SK 플래닛에서 자체 개발한 <strong>AI 기반 영상 생성 B2B 서비스</strong>로, 기업의 광고 영상을 쉽고 빠르게 제작할 수 있는 서비스입니다(2024년 9월 30일 출시하여 2025년 5월 현재 서비스 중). OpenAI의 GPT 모델 및 API(이하 GPT)와 Google Cloud Text-to-Speech AI(이하 Google TTS)를 적용하였으며, 서비스 동작 방식은 다음과 같습니다.</p>\n<ol>\n<li>사용자가 기업명을 입력하면(예: SK플래닛, SK planet 등)</li>\n<li>GPT-4o(예시)를 통해 해당 기업의 카테고리를 분류하고</li>\n<li>마케팅 문구와 TTS용 문구를 생성합니다.</li>\n<li>이 후 Google TTS를 활용해 음성을 만들고,</li>\n<li>사전에 준비된 템플릿에 이미지를 합성하여 최종 영상을 생성합니다.</li>\n</ol>\n<p>이 모든 과정을 위해 사용자가 입력해야 할 것은 단 하나, <strong>'기업 이름'</strong> 뿐입니다.</p>\n<p>사용자는 이 영상을 'V비즈링', 'V비즈프로필' 등 통신사 부가 서비스에 설정해 전화를 걸거나 받을 때마다 기업을 홍보할 수 있게 됩니다(아래 예시 이미지를 참고하세요).\n</br>\n</br>\n</br></p>\n<p><img src=\"/c9e6f847e8ab4a78f9fa6bc50b476241/aimoment_example1.gif\" alt=\"aimoment_example1\">\n</br>\n(💡 블로그에 직접 영상을 올리기 어려워 GIF로 대체했어요!\n영상 길이가 길다 보니 로딩을 고려해서 반복 주기를 좀 짧게 조정했는데, 덕분에(?) 조금 급하게 느껴질 수 있어요.\n실제 영상은 더 자연스럽고 부드럽답니다 😊)</p>\n<h2>2. AI를 만드는 두 가지 관점 : 기획자와 개발자의 협업기</h2>\n<p>AI Moment 과제를 진행하면서, 사업팀과 개발팀의 역할을 아래와 같이 명확하게 구분하었습니다:</p>\n<ul>\n<li>사업팀: 프롬프트를 설계하고 \"어떻게 하면 GPT가 더 매끄럽고 예쁘게 말하게 할 수 있을까\"를 고민</li>\n<li>개발팀: 형식과 구조를 표준화한 뒤, 검증과 예외 처리를 거쳐 API로 통합하며 \"어떻게 하면 항상 같은 방식으로 일관되게 말하게 할 수 있을까\"를 고민</li>\n</ul>\n<p>프롬프트 설계와 구현 영역을 분리하여, 각 팀은 자신의 전문성을 바탕으로 협력할 수 있었고, 따라서 기획과 기술 역량을 함께 성장시키는 경험을 할 수 있었습니다.</p>\n<h2>3. LLM으로 서비스 구현 시 마주친 세 가지 문제</h2>\n<h4>(a) 응답의 비결정성 (Non-determinism)</h4>\n<p>GPT는 똑똑하지만, 항상 우리가 원하는 형식으로 응답해주지는 않습니다. 예를 들어, JSON 형식으로 답해달라고 요청해도 \"Sure! Here's the result:\" 같은 문장이 앞에 붙는 경우가 흔히 발생하죠.</p>\n<p>하지만 우리는 GPT의 응답을 단순한 대화용이 아닌, 서비스 코드에서 직접 파싱하고 활용해야 했기 때문에, 응답 형식의 일관성과 데이터 파싱의 안정성이 무엇보다 중요했습니다.</p>\n<p>✅ 해결 방법 : Pydantic 모델과 PromptTemplate 활용\n이 문제를 해결하기 위해, 우리는 Pydantic 모델과 PromptTemplate의 format_instructions 기능을 적극 활용해 GPT가 명확한 형식을 따르도록 유도하는 구조를 설계했습니다.</p>\n<p>Python 코드:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prompt <span class=\"token operator\">=</span> PromptTemplate<span class=\"token punctuation\">(</span>\n    template<span class=\"token operator\">=</span>template_text<span class=\"token punctuation\">,</span>\n    input_variables<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"query\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    partial_variables<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"format_instructions\"</span><span class=\"token punctuation\">:</span> format_instructions<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n \nchain <span class=\"token operator\">=</span> prompt <span class=\"token operator\">|</span> model <span class=\"token operator\">|</span> print_result<span class=\"token punctuation\">(</span><span class=\"token string\">\"Category Prompt Result\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">|</span> output_parser\n \n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Category</span><span class=\"token punctuation\">(</span>BaseModel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token builtin\">id</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"카테고리 ID\"</span><span class=\"token punctuation\">)</span>\n    categoryName<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"카테고리 이름\"</span><span class=\"token punctuation\">)</span>\n    reason<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"이 카테고리를 추천한 이유\"</span><span class=\"token punctuation\">)</span>\n    inputText<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"사용자 입력 원문\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Prompt 구조:</p>\n<div class=\"gatsby-highlight\" data-language=\"prompt\"><pre class=\"language-prompt\"><code class=\"language-prompt\">위의 모든 결과들을 꼭! 아래 &lt;결과 양식&gt; 포맷에 맞추어 답변해야 한다.\n결과 양식은 json 형식에 맞게 return 되어야 한다.\n\n&lt;결과 양식&gt;\nid: [id]\ncategoryName: [카테고리 명]\nreason: [추천한 이유]\ninputText: [사용자가 입력한 문구]\n\n&lt;예시&gt;\n&quot;id&quot;: &quot;243&quot;,\n&quot;categoryName&quot;: &quot;가공식품_수산&quot;,\n&quot;reason&quot;: &quot;털보수산은 수산물과 관련된 제품이나 서비스를 제공하는 기업으로, 이 카테고리에 적합합니다.&quot;,\n&quot;inputText&quot;: &quot;신선한 털보수산&quot;\n\n{query}\n{format_instructions}</code></pre></div>\n<p>💡 Pydantic이란?\n</br>\nPython 타입 힌트를 활용해 데이터의 유효성을 자동으로 검사하고, 직렬화 및 역직렬화를 간단하게 처리할 수 있는 라이브러리입니다. 타입 자동 변환, 필드 설명, 기본값 지정 등을 통해 코드의 안정성과 가독성을 크게 높여줍니다.</p>\n<h4>(b) 예외 처리</h4>\n<p>위와 같은 구조 덕분에 대부분의 응답은 깔끔하게 파싱되었지만, 간혹 GPT의 응답 형식이 깨지거나 TTS 호출이 실패하는 상황도 발생할 수 있었습니다.</p>\n<p>이를 대비해 기본 카테고리와 문구를 제공하거나 영상 생성을 스킵하는 이른바 '우아한 처리(Graceful Degradation)' 전략도 함께 구현해, 전체 서비스의 안정성과 사용자 경험을 지킬 수 있도록 했습니다.</p>\n<h4>(c) 속도 문제</h4>\n<p>GPT → TTS → FFmpeg로 이어지는 영상 생성 과정은 단계별로 시간이 누적되기 때문에, 속도 지연이 사용자 경험에 영향을 줄 수 있는 부분이었습니다.</p>\n<p>✅ 해결 방법 : <strong>비동기 처리와 Prefix Caching</strong>\n</br>\n이를 완화하기 위해 일부 작업은 비동기 처리로 개선했고, 속도와 비용 최적화를 위한 캐시 전략도 함께 고려했습니다.</p>\n<p>캐시 전략의 일환으로 활용한 것이 바로 OpenAI의 prefix caching 기능이었습니다. 이는 일정 조건을 만족할 경우 동일한 프롬프트의 앞부분을 내부적으로 캐싱하여 재사용하는 것으로, 지연 시간을 최대 80%, 비용도 최대 50%까지 할인해주는 기능입니다.\n</br>\n이 덕분에 중복 요청에 대한 성능과 비용 측면 모두에서 이점을 얻을 수 있었고, 실서비스 최적화에 큰 도움이 되었습니다.</p>\n<p>✨ 참고 사항:\n</br>\nGPT-4o 이상 최신 모델에서 활성화되며 추가 비용 없이 무료로 사용할 수 있습니다!\n</br>\n자세한 내용: OpenAI Prompt Caching 가이드\n<a href=\"https://platform.openai.com/docs/guides/prompt-caching\">https://platform.openai.com/docs/guides/prompt-caching</a></p>\n<p>🎯 thanks to:\n</br>\nprefix caching은 프로젝트 기간 중 참여한 사내 교육을 통해 알게 된 내용으로, 인사이트에 큰 도움이 되었습니다. 좋은 교육을 진행해 주셔서 감사합니다 :)</p>\n<h2>4. 생성형 AI의 결과를 '서비스화'한다는 것</h2>\n<p>개발자 입장에서 생성형 AI는 일종의 새로운 백엔드입니다. 우리가 요청을 던지면 기대한 \"예쁜 응답\"이 아닌, 예상 밖의 말투나 형식으로 결과가 돌아오기도 하죠.\n</br>\n특히 서비스를 운영하는 입장에서 보면, AI의 응답을 그대로 사용자에게 보여줄 수 있는 경우는 거의 없습니다. 그래서 개발자는 단순히 API만 연결하는 역할을 넘어, 사용자에게 전달 가능한 형태로 다듬는 일에 꽤 많은 노력이 필요합니다.</p>\n<h4>(a) 판단은 결국 사람이 한다</h4>\n<p>GPT는 아무리 정교하더라도, 문장이 브랜드 이미지에 어울리는지 또는 문맥상 어색하지 않은지를 스스로 판단하지 못합니다. 이럴 때는 최소한의 룰 기반 필터링 로직을 통해 너무 짧거나 긴 문장, 부적절한 표현 등을 사전에 걸러내는 장치를 두는 방법도 있습니다.</p>\n<h4>(b) 영상 템플릿에 들어가는 문구 처리</h4>\n<p>영상에 문구를 삽입할 때, 너무 긴 문장으로 레이아웃이 깨지거나 텍스트가 잘리는 문제가 생길 수 있습니다. 이런 경우, 다음과 같은 정책을 도입할 수 있습니다:</p>\n<ul>\n<li>문구의 길이 제한</li>\n<li>자동 줄바꿈 처리</li>\n<li>자막 분할 기준 조정</li>\n<li>TTS 재생 시간을 고려한 문장 길이나 호흡 조정</li>\n</ul>\n<h4>(c) 리소스 정리 자동화</h4>\n<p>AI가 만든 결과로 영상이나 파일을 생성한 뒤에는 다음과 같은 마무리 작업이 필요합니다:</p>\n<ul>\n<li>임시 파일 정리</li>\n<li>메모리 및 스토리지 회수</li>\n<li>로그 정리</li>\n</ul>\n<p>이런 부분까지 자동화해 두어야, 서비스가 안정적으로 운영될 수 있습니다.\n이처럼, 생성형 AI를 활용한 서비스는 '좋은 결과를 얻는 것'만큼이나 그 결과를 실제 서비스로 연결하는 과정이 중요합니다. 결국 서비스 품질은 개발자의 손에서 완성된다는 걸 다시 한 번 느꼈습니다.</p>\n<h2>5. 더 믿음직한 AI Moment가 되기 위해서는?</h2>\n<p>서비스를 운영하다 보면 자연스럽게 이런 생각이 듭니다:</p>\n<ul>\n<li>\"GPT가 만든 문장이 과연 괜찮은가?\"</li>\n<li>\"지금 결과가 지난주보다 더 좋아진 걸까?\"</li>\n</ul>\n<p>이것은 단순히 '동작했냐 아니냐'의 차원이 아니라, 문장이 얼마나 자연스럽고, 그 회사의 브랜드나 마케팅 방향에 얼마나 잘 부합하며, 얼마나 빠르고 안정적으로 동작했는지를 정성적 + 정량적 관점에서 함께 평가해야 하는 문제입니다.\n</br>\n그래서 저희는 앞으로 아래와 같은 방향으로 테스트 전략을 정립해 보려고 합니다:</p>\n<p>✅ 정성적 평가 (Qualitative Evaluation)</p>\n<ul>\n<li>TTS 결과를 직접 들어보고, 말투나 억양이 자연스러운지 판단</li>\n<li>분류된 카테고리와 생성된 문구가 브랜드 이미지에 어울리는지 리뷰</li>\n<li>프롬프트를 수정할 때 응답 결과가 어떻게 달라지는지 비교 실험</li>\n</ul>\n<p>✅ 정량적 평가 (Quantative Evaluation)</p>\n<ul>\n<li>응답 실패율, 응답 지연 시간(latency) 측정 및 개선</li>\n<li>동일 입력에 대한 분류 결과의 정확도를 수치로 비교</li>\n<li>영상을 다시 생성하거나 변형해 재활용한 비율을 측정해 만족도와 실사용도 평가</li>\n</ul>\n<p>AI는 사람이 아니기 때문에 단지 '좋은 답'을 내는 것이 아니라 확률에 의한 '타당한 답'을 냅니다. 그것을 <strong>좋은 답</strong>으로 판정해 주는 주체는 바로 사람이죠. 그래서 우리는 앞으로도 사람의 감각과 시스템의 수치를 함께 활용하여 AI 품질을 높이기 위해 계속 실험하고자 합니다.</p>\n<h2>✨ 마무리하며 – AI는 친구, 개발자는 통역가</h2>\n<p>AI는 점점 똑똑해지고 있습니다. 하지만 그 결과물을 API로서 안정적으로 사용하고, 사용자 경험으로 연결해주는 건 여전히 <strong>개발자</strong>의 역할입니다.\n프롬프트를 고민하는 기획자, 그 결과를 다듬고 구조화하는 개발자, 그리고 이를 서비스로 만들어내는 팀 전체가 함께 고민해야 고객이 만족하는 생성형 AI 서비스가 만들어진다고 생각합니다.\n</br></br>\nAI Moment는 아직도 성장 중이며, 저희는 그 안에서 <strong>AI와 인간 사이를 잇는 개발자</strong>로서의 역할을 계속 탐구해 보고 싶습니다. 읽어 주셔서 감사합니다.</p>","frontmatter":{"title":"생성형 AI를 활용한 마케팅 영상 제작 - AI Moment 개발 사례","date":"May 29, 2025","description":"생성형 AI를 활용한 마케팅 영상 제작 - AI Moment 개발 사례","author":"shinys"}},"previous":{"fields":{"slug":"/skp-prompthon24/"},"frontmatter":{"title":" '우리 회사 서비스 캐릭터들이 AI를 만나면 어떤 아이들이 될까?' (feat. SKP 멀티 LLM 플레이그라운드 ＆ AI 프롬프톤 사례 공유)"}},"next":null},"pageContext":{"id":"9fd04d10-3c46-570b-921d-96a92939613b","previousPostId":"0b4d3249-853c-58c9-9d8b-bae1d2ac318c","nextPostId":null}},"staticQueryHashes":["2841359383"],"slicesMap":{}}